{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2935229c-1a70-442b-94b1-a533accb86d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            id                          start  \\\n",
      "0  11390_2012_01_05_17_06_01_0  2012-01-05 05:06:01.000000000   \n",
      "1  11390_2012_01_05_17_19_01_0  2012-01-05 05:19:01.000000000   \n",
      "2  11390_2012_01_05_17_19_01_1  2012-01-06 05:19:00.000000000   \n",
      "3  11390_2012_01_06_17_20_58_0  2012-01-06 05:20:58.000000000   \n",
      "4  11390_2012_01_04_07_22_01_0  2012-01-03 19:22:01.000000000   \n",
      "\n",
      "                             end     peak_flux  \n",
      "0  2012-01-05 17:06:01.000000000  8.000000e-07  \n",
      "1  2012-01-05 17:19:01.000000000  1.647059e-06  \n",
      "2  2012-01-06 17:19:00.000000000  1.647059e-06  \n",
      "3  2012-01-06 17:20:58.000000000  1.164706e-06  \n",
      "4  2012-01-04 07:22:01.000000000  2.235294e-06  \n",
      "Train shape: (8336, 4)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "# FIX: Remove double SDOBenchmark-data-full path\n",
    "DATA_DIR = r\"F:\\DevProjects\\Projects\\Solar_Flare_Prediction\\data\\SDOBenchmark-data-full\"\n",
    "\n",
    "TRAIN_IMG_DIR = os.path.join(DATA_DIR, \"training\")\n",
    "TEST_IMG_DIR  = os.path.join(DATA_DIR, \"test\")\n",
    "\n",
    "TRAIN_CSV = os.path.join(TRAIN_IMG_DIR, \"train.csv\")\n",
    "TEST_CSV  = os.path.join(TEST_IMG_DIR,  \"test.csv\")\n",
    "\n",
    "# Read CSVs with correct header settings\n",
    "train_df = pd.read_csv(TRAIN_CSV, header=None, \n",
    "                       names=[\"id\", \"start\", \"end\", \"peak_flux\"])\n",
    "test_df  = pd.read_csv(TEST_CSV, header=None, \n",
    "                       names=[\"id\", \"start\", \"end\", \"peak_flux\"])\n",
    "\n",
    "# Convert peak_flux to numeric\n",
    "train_df[\"peak_flux\"] = pd.to_numeric(train_df[\"peak_flux\"], errors=\"coerce\")\n",
    "test_df[\"peak_flux\"]  = pd.to_numeric(test_df[\"peak_flux\"],  errors=\"coerce\")\n",
    "\n",
    "# Drop NaN rows\n",
    "train_df = train_df.dropna(subset=[\"peak_flux\"]).reset_index(drop=True)\n",
    "test_df  = test_df.dropna(subset=[\"peak_flux\"]).reset_index(drop=True)\n",
    "\n",
    "print(train_df.head())\n",
    "print(\"Train shape:\", train_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dbdb3675-3483-40b6-9dde-70352122559e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample_dir(img_root, sample_id):\n",
    "    \"\"\"\n",
    "    sample_id like: 11390_2012_01_05_17_19_01_0\n",
    "    Returns: img_root/11390/2012_01_05_17_19_01_0\n",
    "    \"\"\"\n",
    "    region, rest = sample_id.split(\"_\", 1)\n",
    "    return os.path.join(img_root, region, rest)\n",
    "\n",
    "CHANNEL_TAGS = [\"94\", \"131\", \"171\", \"193\", \"211\",\n",
    "                \"304\", \"335\", \"1700\", \"continuum\", \"magnetogram\"]\n",
    "\n",
    "def parse_file(fname):\n",
    "    \"\"\"\n",
    "    Example: 2012-01-05T051901__171.jpg\n",
    "    Returns: (2012-01-05T051901, 171)\n",
    "    \"\"\"\n",
    "    base = fname[:-4]  # drop .jpg\n",
    "    ts_str, tag = base.split(\"__\")\n",
    "    return ts_str, tag\n",
    "\n",
    "def load_sample_from_id(img_root, sample_id):\n",
    "    \"\"\"\n",
    "    Load all 40 images (4 timestamps x 10 channels) for one sample.\n",
    "    Returns: (40, 256, 256) array\n",
    "    \"\"\"\n",
    "    sample_dir = get_sample_dir(img_root, sample_id)\n",
    "    fnames = sorted(os.listdir(sample_dir))\n",
    "\n",
    "    # Group files by timestamp\n",
    "    by_ts = {}\n",
    "    for f in fnames:\n",
    "        ts_str, tag = parse_file(f)\n",
    "        by_ts.setdefault(ts_str, {})[tag] = f\n",
    "\n",
    "    # Pick up to 4 earliest timestamps\n",
    "    ts_list = sorted(by_ts.keys())[:4]\n",
    "\n",
    "    imgs = []\n",
    "    for ts in ts_list:\n",
    "        tag2file = by_ts[ts]\n",
    "        for tag in CHANNEL_TAGS:\n",
    "            if tag in tag2file:\n",
    "                img_path = os.path.join(sample_dir, tag2file[tag])\n",
    "                img = Image.open(img_path).convert(\"L\")\n",
    "                imgs.append(np.array(img))\n",
    "            else:\n",
    "                # missing channel -> zero image\n",
    "                imgs.append(np.zeros((256, 256), dtype=np.uint8))\n",
    "\n",
    "    imgs = np.array(imgs)  # (n_imgs, 256, 256)\n",
    "    \n",
    "    # Pad to exactly 40 if needed\n",
    "    if imgs.shape[0] < 40:\n",
    "        pad = np.zeros((40 - imgs.shape[0], 256, 256), dtype=np.uint8)\n",
    "        imgs = np.concatenate([imgs, pad], axis=0)\n",
    "    \n",
    "    return imgs[:40]  # ensure exactly 40\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e70c6908-38cb-4d38-a2b3-6fa479d08d3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M/X class distribution in train_df:\n",
      "is_MX\n",
      "0    7822\n",
      "1     514\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "EPS = 1e-9\n",
    "train_df[\"log_peak_flux\"] = np.log10(train_df[\"peak_flux\"].clip(lower=EPS))\n",
    "test_df[\"log_peak_flux\"]  = np.log10(test_df[\"peak_flux\"].clip(lower=EPS))\n",
    "\n",
    "train_df[\"is_MX\"] = (train_df[\"peak_flux\"] >= 1e-5).astype(int)\n",
    "test_df[\"is_MX\"]  = (test_df[\"peak_flux\"]  >= 1e-5).astype(int)\n",
    "\n",
    "print(\"M/X class distribution in train_df:\")\n",
    "print(train_df[\"is_MX\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb8cc4b0-1898-456a-b29a-5347a893f9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SDOBenchmarkDataset(Dataset):\n",
    "    def __init__(self, df, img_root):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.img_root = img_root\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        sample_id = row[\"id\"]\n",
    "        log_peak_flux = row[\"log_peak_flux\"]\n",
    "        is_MX = row[\"is_MX\"]\n",
    "\n",
    "        # Load 40 images\n",
    "        imgs = load_sample_from_id(self.img_root, sample_id)  # (40, 256, 256)\n",
    "        \n",
    "        # Reshape to (T=4, C=10, H=256, W=256)\n",
    "        imgs = imgs.reshape(4, 10, 256, 256)\n",
    "        \n",
    "        # Convert to torch float [0, 1]\n",
    "        imgs = torch.from_numpy(imgs).float() / 255.0\n",
    "\n",
    "        # Targets\n",
    "        reg_target = torch.tensor(log_peak_flux, dtype=torch.float32)\n",
    "        cls_target = torch.tensor(is_MX, dtype=torch.float32)\n",
    "        \n",
    "        return imgs, reg_target, cls_target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "028ce773-5cf9-41a8-b352-11729c47eaab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train batch imgs shape: torch.Size([2, 4, 10, 256, 256])\n",
      "Train batch reg targets (first 2): tensor([-6.1099, -6.4823])\n",
      "Train batch cls targets (first 2): tensor([0., 0.])\n"
     ]
    }
   ],
   "source": [
    "# Use only first 300 samples for fast training\n",
    "subset_df = train_df.iloc[:300].copy()\n",
    "\n",
    "train_df_small, val_df_small = train_test_split(\n",
    "    subset_df,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "train_dataset = SDOBenchmarkDataset(train_df_small, TRAIN_IMG_DIR)\n",
    "val_dataset   = SDOBenchmarkDataset(val_df_small,   TRAIN_IMG_DIR)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True,  num_workers=0)\n",
    "val_loader   = DataLoader(val_dataset,   batch_size=2, shuffle=False, num_workers=0)\n",
    "\n",
    "# Sanity check\n",
    "imgs_batch, reg_t, cls_t = next(iter(train_loader))\n",
    "print(\"Train batch imgs shape:\", imgs_batch.shape)  # Should be [2, 4, 10, 256, 256]\n",
    "print(\"Train batch reg targets (first 2):\", reg_t[:2])\n",
    "print(\"Train batch cls targets (first 2):\", cls_t[:2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "175c24d3-1546-4a42-b801-bdfad4aab3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlareCNNMultiTask(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(10, 32, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, 3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(128, 64)\n",
    "        \n",
    "        # Two heads: regression (log-flux) + classification (M/X)\n",
    "        self.reg_head = nn.Linear(64, 1)\n",
    "        self.cls_head = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B, T=4, C=10, H=256, W=256)\n",
    "        B, T, C, H, W = x.shape\n",
    "        x = x.view(B * T, C, H, W)  # (B*T, 10, 256, 256)\n",
    "\n",
    "        # Conv blocks\n",
    "        x = self.pool(F.relu(self.conv1(x)))          # (B*T, 32, 128, 128)\n",
    "        x = self.pool(F.relu(self.conv2(x)))          # (B*T, 64, 64, 64)\n",
    "        x = self.pool(F.relu(self.conv3(x)))          # (B*T, 128, 32, 32)\n",
    "\n",
    "        # Global average pooling\n",
    "        x = F.adaptive_avg_pool2d(x, 1)               # (B*T, 128, 1, 1)\n",
    "        x = x.view(B, T, 128)                         # (B, T=4, 128)\n",
    "        x = x.mean(dim=1)                             # (B, 128)\n",
    "\n",
    "        # FC layer\n",
    "        x = F.relu(self.fc1(x))                       # (B, 64)\n",
    "\n",
    "        # Two outputs\n",
    "        reg_out = self.reg_head(x).squeeze(-1)        # (B,)\n",
    "        cls_logit = self.cls_head(x).squeeze(-1)      # (B,)\n",
    "        \n",
    "        return reg_out, cls_logit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "485242f9-2b93-46e5-9ff3-0f441a6b7108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "\n",
    "model = FlareCNNMultiTask().to(device)\n",
    "\n",
    "reg_criterion = nn.L1Loss()                    # MAE for regression\n",
    "cls_criterion = nn.BCEWithLogitsLoss()         # BCE for classification\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b05bb2c-021c-4547-af61-9360e09e6e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, loader, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    for imgs, reg_t, cls_t in loader:\n",
    "        imgs = imgs.to(device)\n",
    "        reg_t = reg_t.to(device)\n",
    "        cls_t = cls_t.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        reg_out, cls_logit = model(imgs)\n",
    "\n",
    "        reg_loss = reg_criterion(reg_out, reg_t)\n",
    "        cls_loss = cls_criterion(cls_logit, cls_t)\n",
    "        loss = reg_loss + cls_loss\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * imgs.size(0)\n",
    "    \n",
    "    return total_loss / len(loader.dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b9f102c-db7a-432f-a352-2aa582475a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_metrics(model, loader, device):\n",
    "    model.eval()\n",
    "    reg_preds, reg_trues = [], []\n",
    "    cls_probs, cls_trues = [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for imgs, reg_t, cls_t in loader:\n",
    "            imgs = imgs.to(device)\n",
    "            reg_t = reg_t.to(device)\n",
    "            cls_t = cls_t.to(device)\n",
    "\n",
    "            reg_out, cls_logit = model(imgs)\n",
    "            prob = torch.sigmoid(cls_logit)\n",
    "\n",
    "            reg_preds.append(reg_out.cpu())\n",
    "            reg_trues.append(reg_t.cpu())\n",
    "            cls_probs.append(prob.cpu())\n",
    "            cls_trues.append(cls_t.cpu())\n",
    "\n",
    "    reg_preds = torch.cat(reg_preds)\n",
    "    reg_trues = torch.cat(reg_trues)\n",
    "    cls_probs = torch.cat(cls_probs)\n",
    "    cls_trues = torch.cat(cls_trues)\n",
    "\n",
    "    # Regression metrics\n",
    "    log_mae = torch.mean(torch.abs(reg_preds - reg_trues)).item()\n",
    "    flux_pred = 10 ** reg_preds\n",
    "    flux_true = 10 ** reg_trues\n",
    "    flux_mae = torch.mean(torch.abs(flux_pred - flux_true)).item()\n",
    "\n",
    "    # Classification metrics\n",
    "    cls_pred = (cls_probs >= 0.5).int().numpy()\n",
    "    cls_true = cls_trues.int().numpy()\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        cls_true, cls_pred, average=\"binary\", zero_division=0\n",
    "    )\n",
    "    \n",
    "    return log_mae, flux_mae, precision, recall, f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dc0679da-976f-4db8-93e9-325875bd9668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: train_loss=4.649e+00, val_log_MAE=1.734e+00, val_flux_MAE=4.527e-06, prec=0.000, rec=0.000, f1=0.000\n",
      "Epoch 2: train_loss=2.048e+00, val_log_MAE=1.681e+00, val_flux_MAE=4.736e-06, prec=0.000, rec=0.000, f1=0.000\n",
      "Epoch 3: train_loss=2.039e+00, val_log_MAE=1.689e+00, val_flux_MAE=4.617e-06, prec=0.000, rec=0.000, f1=0.000\n",
      "Epoch 4: train_loss=1.991e+00, val_log_MAE=1.655e+00, val_flux_MAE=4.800e-06, prec=0.000, rec=0.000, f1=0.000\n",
      "Epoch 5: train_loss=1.986e+00, val_log_MAE=1.662e+00, val_flux_MAE=5.141e-06, prec=0.000, rec=0.000, f1=0.000\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 5\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    train_loss = train_one_epoch(model, train_loader, optimizer, device)\n",
    "    val_log_mae, val_flux_mae, prec, rec, f1 = eval_metrics(model, val_loader, device)\n",
    "    \n",
    "    print(f\"Epoch {epoch}: train_loss={train_loss:.3e}, \"\n",
    "          f\"val_log_MAE={val_log_mae:.3e}, val_flux_MAE={val_flux_mae:.3e}, \"\n",
    "          f\"prec={prec:.3f}, rec={rec:.3f}, f1={f1:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9136b9de-7527-4850-9cf4-19b8ace9301d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint to: models\\flare_cnn_multitask_subset_e5.pth\n"
     ]
    }
   ],
   "source": [
    "CHECKPOINT_DIR = \"models\"\n",
    "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
    "\n",
    "ckpt_path = os.path.join(CHECKPOINT_DIR, \"flare_cnn_multitask_subset_e5.pth\")\n",
    "torch.save({\n",
    "    \"model_state_dict\": model.state_dict(),\n",
    "    \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "    \"epoch\": EPOCHS,\n",
    "}, ckpt_path)\n",
    "\n",
    "print(\"Saved checkpoint to:\", ckpt_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
